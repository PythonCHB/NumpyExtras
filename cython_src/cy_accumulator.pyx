#!/usr/bin/env python

"""
accumulator class

Designed to be used as an expandable numpy array, to accumulate values, rather
than a python list.

Note that slices return copies, rather than views, unlike regular numpy arrays.
This is so that the buffer can be re-allocated without messing up any views.

"""
import cython
import numpy as np

cimport numpy as cnp

## A couple constants for how this behaves -- should be changeable (i.e. instance attributes)
# smallest buffer to initialize -- 16 elements
cdef Py_ssize_t DEFAULT_BUFFER_SIZE = 128

# how much should the buffer grow when appending..
# array.array uses 1+1/16 -- that seems small to me.
# NOTE: performance isn't very dependent on this.
cdef float BUFFER_EXTEND_SIZE = 1.25


from libc.stdlib cimport malloc, realloc, free
from libc.string cimport memcpy

## stuff from standard cpython API
from cpython cimport Py_INCREF

## initialize numpy ('cause I'm using the numpy API)
cnp.import_array()

## this should be in the numpy.pxd, but there are some weirdness
## DAG wasn't sure about, so it's commented out    
cdef extern from "numpy/arrayobject.h":
    ctypedef struct PyTypeObject:
        pass
    PyTypeObject PyArray_Type
    object PyArray_NewFromDescr(PyTypeObject *type_,
                                cnp.dtype dtype,
                                int N_dims,
                                cnp.npy_intp *dims,
                                cnp.npy_intp *strides,
                                void *data,
                                int flags,
                                void *obj)


cdef class Accumulator:
    
    cdef Py_ssize_t length
    cdef Py_ssize_t __buffer_length
    cdef Py_ssize_t itemsize
    cdef char* __buffer 
    cdef short __type_case
    cdef cnp.dtype dtype
    # A few parameters
    def __init__(self, input_object=(), dtype=np.int32):
        """
        Proper docs here
        
        note: a scalar accumulator doesn't really make sense, so you get a length-1 array instead.
        """
        
        # Use numpy machinery to convert
        #   any (usable) input to something usable
        
        cdef cnp.ndarray input = np.asarray(input_object, dtype=dtype)
        
        if input.ndim > 1:
            raise ValueError("accumulator only works with 1-d data")
        elif input.ndim == 0: #it's a numpy scalar
            input = input.reshape((1,),) # make it a 1d array with one element
        # it's now a 1-d array
        self.length = input.shape[0]
        
        self.dtype = np.dtype(dtype) # convert to an actual dtype object (rather than a type object)

        # check and assign all the special case dtypes
        ############################################
        ## NOTE: The following if block generated by build_type_code.py 
        if self.dtype == np.int8:
            self.__type_case = cnp.NPY_INT8
        elif self.dtype == np.int16:
            self.__type_case = cnp.NPY_INT16
        elif self.dtype == np.int32:
            self.__type_case = cnp.NPY_INT32
        elif self.dtype == np.int64:
            self.__type_case = cnp.NPY_INT64
        elif self.dtype == np.uint8:
            self.__type_case = cnp.NPY_UINT8
        elif self.dtype == np.uint16:
            self.__type_case = cnp.NPY_UINT16
        elif self.dtype == np.uint32:
            self.__type_case = cnp.NPY_UINT32
        elif self.dtype == np.uint64:
            self.__type_case = cnp.NPY_UINT64
        elif self.dtype == np.float32:
            self.__type_case = cnp.NPY_FLOAT32
        elif self.dtype == np.float64:
            self.__type_case = cnp.NPY_FLOAT64
        elif self.dtype == np.complex64:
            self.__type_case = cnp.NPY_COMPLEX64
        elif self.dtype == np.complex128:
            self.__type_case = cnp.NPY_COMPLEX128
        else:
            raise NotImplementedError("This dtype is not supported")

        ## End Generated Code
        #####################################
        ## need code here for numpy user-defined dtypes
        
        self.itemsize = cnp.PyArray_ITEMSIZE(input)
        
        self.__buffer_length = max( <Py_ssize_t> (self.length * BUFFER_EXTEND_SIZE),
                                    DEFAULT_BUFFER_SIZE)

        # Allocate the buffer
        self.__buffer = <char*> malloc(self.itemsize * self.__buffer_length)# buffer length in number of elements
        if self.__buffer is NULL:
            # the malloc failed
            raise MemoryError
        # transfer the data from the numpy array to the buffer
        memcpy(self.__buffer, cnp.PyArray_DATA( input ), self.length*self.itemsize)
                
    def __dealloc__(self):
        """
        called when the object is garbage collected
        
        This frees the buffer memory
        """
        # If we successfully created an instance of the buffer, free it
        # note: apparently, there is some chance that this class could have been
        # partially initialized, then this destructor called.
        if self.__buffer is not NULL:
            free( self.__buffer )

    def append(self, item):
        """
        add a new item to the end of the array
        """
        ## check if the buffer is big enough:
        if self.length >= self.__buffer_length:
            ## need to re-allocate a bigger buffer here
            #raise NotImplementedError("not able to grow the buffer yet")
            self.resize_buffer( <Py_ssize_t> (self.length * BUFFER_EXTEND_SIZE) )

        ## check for type for the cast ...
#        ## fast code for the numpy types    
#        if self.__type_case == cnp.NPY_UINT8:
#            (<cnp.uint8_t*> self.__buffer)[self.length] = <cnp.uint8_t> item
#        elif self.__type_case == cnp.NPY_INT32:
#            (<cnp.int32_t*> self.__buffer)[self.length] = <cnp.int32_t> item
#        elif self.__type_case == cnp.NPY_FLOAT32:
#            (<cnp.float32_t*> self.__buffer)[self.length] = <cnp.float32_t> item

        # check and assign all the special case dtypes
        ############################################
        ## NOTE: The following if block generated by build_type_code.py 
        if self.__type_case == cnp.NPY_INT8:
            (<cnp.int8_t*> self.__buffer)[self.length] = <cnp.int8_t> item
        elif self.__type_case == cnp.NPY_INT16:
            (<cnp.int16_t*> self.__buffer)[self.length] = <cnp.int16_t> item
        elif self.__type_case == cnp.NPY_INT32:
            (<cnp.int32_t*> self.__buffer)[self.length] = <cnp.int32_t> item
        elif self.__type_case == cnp.NPY_INT64:
            (<cnp.int64_t*> self.__buffer)[self.length] = <cnp.int64_t> item
        elif self.__type_case == cnp.NPY_UINT8:
            (<cnp.uint8_t*> self.__buffer)[self.length] = <cnp.uint8_t> item
        elif self.__type_case == cnp.NPY_UINT16:
            (<cnp.uint16_t*> self.__buffer)[self.length] = <cnp.uint16_t> item
        elif self.__type_case == cnp.NPY_UINT32:
            (<cnp.uint32_t*> self.__buffer)[self.length] = <cnp.uint32_t> item
        elif self.__type_case == cnp.NPY_UINT64:
            (<cnp.uint64_t*> self.__buffer)[self.length] = <cnp.uint64_t> item
        elif self.__type_case == cnp.NPY_FLOAT32:
            (<cnp.float32_t*> self.__buffer)[self.length] = <cnp.float32_t> item
        elif self.__type_case == cnp.NPY_FLOAT64:
            (<cnp.float64_t*> self.__buffer)[self.length] = <cnp.float64_t> item
        elif self.__type_case == cnp.NPY_COMPLEX64:
            (<cnp.complex64_t*> self.__buffer)[self.length] = <cnp.complex64_t> item
        elif self.__type_case == cnp.NPY_COMPLEX128:
            (<cnp.complex128_t*> self.__buffer)[self.length] = <cnp.complex128_t> item
        else:
            raise NotImplementedError("This dtype is not supported for append")
        ## End Generated Code
        #####################################

#            elif self._case == cnp.NPY_VOID:
#                item_array = item
#                cnp.PyArray_ITEMSIZE(item_array)
#                cnp.PyArray_DATA(item_array)
#                <void*> self.__buffer[self.length * self.itemsize] = item_array
#        else:
#            ## to find special numpy types
#            #cdef cnp.ndarray item_array
#            #item_array = np.asarray(item, dtype=self.dtype)
#            raise NotImplementedError
        self.length += 1

    def resize_buffer(self, newsize):
        """
        resize the internal buffer
        
        You might want to do this manually to speed things up if you know you want it
        to be a lot bigger eventually.
        
        Otherwise, it's called automatically from append() and extend() as needed
        
        """
        <Py_ssize_t> newsize
        if newsize < self.length:
            raise ValueError("accumulator buffer cannot be made smaller that the length of the data")
        self.__buffer_length = newsize
        self.__buffer = <char*> realloc( self.__buffer, self.__buffer_length*self.itemsize)
        if self.__buffer is NULL:
            # the malloc failed
            raise MemoryError("couldn't allocate a new buffer")


    property dtype:
        def __get__(self):
            return self.dtype
        def __set__(self, value):
            raise AttributeError("Can not set the dtype after initilization")

    property buffer_length:
        def __get__(self):
            return self.__buffer_length
        def __set__(self, value):
            self.resize_buffer(value)

#    ##fixme: 
#    ## using @property seems to give a getter, but setting then overrides it
#    ## which seems terribly prone to error.
#    @property
#    def dtype(self):
#        return self.__buffer.dtype
#
#    @property
#    def buffersize(self):
#        """
#        the size of the internal buffer
#        """
#        return self.__buffer.size
#
#    @property
#    def shape(self):
#        """
#        To be compatible with ndarray.shape
#        (only the getter!) 
#        """
#        return (self.length,)
    
    def __len__(self):
        return self.length
        
    def __array__(self, dtype=None):
        """
        a.__array__(|dtype) -> copy of array.
    
        Always returns a copy array, so that buffer doesn't have any references to it.
        """
        if dtype is not None:
            raise NotImplementedError("can only create an array of the same dtype")
        
        cdef cnp.ndarray new_array
        ## note: this could get fancier for higher dimension arrays...
        cdef cnp.npy_intp *dims = [self.length]
        cdef cnp.npy_intp *strides = [self.itemsize]
                
        Py_INCREF(self.dtype)
        result = PyArray_NewFromDescr(&PyArray_Type,
                                      self.dtype,
                                      1,
                                      dims,
                                      strides,
                                      self.__buffer,
                                      cnp.NPY_ENSURECOPY | cnp.NPY_C_CONTIGUOUS,
                                      NULL)
        return result

#    def extend(self, items):
#        """
#        add a sequence of new items to the end of the array
#        """
#        try:
#            self.__buffer[self.length:self.length+len(items)] = items
#            self.length += len(items)
#        except ValueError: # the buffer is not big enough
#            self.resize_buffer((self.length+len(items))*BUFFER_EXTEND_SIZE)
#            self.extend(items)
#
#    def fitbuffer(self):
#        """
#        re-sizes the buffer so that it fits the data, rather than having extra space
#
#        """
#        self.__buffer.resize(self.length)
#        
    def __getitem__(self, n):
        print "in __get_item__ -- index is:", n
        cdef int index
        cdef int start, stop

        cdef cnp.ndarray new_array
        ## note: this could get fancier for higher dimension arrays...
        cdef cnp.npy_intp *dims
        cdef cnp.npy_intp *strides
        cdef void *start_p
        # first check if we have a slice or an index:
        if isinstance(n, slice):
            # a slice returns an array:
            print "got a slice: %s, %s, %s", n.start, n.stop, n.step
            start = n.start
            stop = n.stop
            if n.step is None:
                raise NotImplementedError("does not support steps in slices yet...")
            else:
                print "returning  new array with the slice"
                # return a new array with a copy of the data:
                
                Py_INCREF(self.dtype)
                dims = [stop - start]
                strides = [self.itemsize]
                start_p = self.__buffer + start*self.itemsize
                result = PyArray_NewFromDescr(&PyArray_Type,
                                              self.dtype,
                                              1,
                                              dims,
                                              strides,
                                              start_p,
                                              cnp.NPY_ENSURECOPY | cnp.NPY_C_CONTIGUOUS,
                                              NULL)
                return result

            # Expand the slice object using range()
            # to a maximum of eight items.
            # return [self[x] for x in 
            #         range(*n.indices(8))]
        else:
            index = n
            if index > self.length-1 or index < -self.length:
                raise IndexError("index out of range")
            elif index < 0 :
                index = self.length+index
            print "returning index:", index

        ## special case code for each dtype:
        ############################################
        ## NOTE: The following if block generated by build_type_code.py 
        if self.__type_case == cnp.NPY_INT8:
            item = (<cnp.int8_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_INT16:
            item = (<cnp.int16_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_INT32:
            item = (<cnp.int32_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_INT64:
            item = (<cnp.int64_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_UINT8:
            item = (<cnp.uint8_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_UINT16:
            item = (<cnp.uint16_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_UINT32:
            item = (<cnp.uint32_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_UINT64:
            item = (<cnp.uint64_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_FLOAT32:
            item = (<cnp.float32_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_FLOAT64:
            item = (<cnp.float64_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_COMPLEX64:
            item = (<cnp.complex64_t*> self.__buffer)[index]
        elif self.__type_case == cnp.NPY_COMPLEX128:
            item = (<cnp.complex128_t*> self.__buffer)[index]
        else:
            raise NotImplementedError("This dtype is not supported for indexing")

        ## End Generated Code
        #####################################

        return item
    
    def __str__(self):
        return self.__array__().__str__()
    def __repr__(self):
        return  "Accumulator%s"%self.__array__().__repr__()[5:]
